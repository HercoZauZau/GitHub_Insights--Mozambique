{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e4b2d0-6a85-4c5d-8df6-2e2dd49de6a5",
   "metadata": {},
   "source": [
    "# Documentação: Coleta de Repositórios Curtidos (Starred) do GitHub\n",
    "\n",
    "## Introdução\n",
    "Este script recupera informações sobre os repositórios curtidos (starred) pelos usuários do GitHub de forma assíncrona. Ele filtra apenas as chaves relevantes e salva os dados processados em arquivos CSV.\n",
    "\n",
    "## Dependências\n",
    "Antes de executar o script, instale as bibliotecas necessárias:\n",
    "\n",
    "```bash\n",
    "pip install aiohttp nest_asyncio pandas tqdm\n",
    "```\n",
    "\n",
    "## Estrutura do Script\n",
    "\n",
    "### 1. Configuração do Loop Assíncrono\n",
    "```python\n",
    "nest_asyncio.apply()\n",
    "```\n",
    "Em ambientes como Jupyter Notebook, é necessário aplicar `nest_asyncio` para evitar conflitos com o loop de eventos assíncrono.\n",
    "\n",
    "### 2. Definição das Chaves Relevantes\n",
    "```python\n",
    "chaves_relevantes = [\"id\", \"name\", \"full_name\", \"owner_id\", \"html_url\", \"description\", \"fork\", \"created_at\", \"updated_at\", \"pushed_at\", \"homepage\", \"size\", \"stargazers_count\", \"watchers_count\", \"language\", \"forks_count\", \"open_issues_count\", \"license_key\", \"license_name\", \"topics\", \"default_branch\"]\n",
    "```\n",
    "Define quais informações serão extraídas dos repositórios curtidos pelos usuários do GitHub.\n",
    "\n",
    "### 3. Função `flatten_dict`\n",
    "```python\n",
    "def flatten_dict(data, parent_key=\"\"):\n",
    "```\n",
    "Essa função achata um dicionário aninhado, transformando listas em strings separadas por vírgulas e mantendo apenas as chaves relevantes.\n",
    "\n",
    "### 4. Função `fetch_repos_for_user`\n",
    "```python\n",
    "async def fetch_repos_for_user(session, user_id, semaphore, timeout=1000):\n",
    "```\n",
    "Essa função busca os repositórios curtidos por um usuário no GitHub, tratando a paginação e aplicando a função `flatten_dict` para manter apenas as chaves relevantes.\n",
    "\n",
    "### 5. Função `get_repository_data_async`\n",
    "```python\n",
    "async def get_repository_data_async(user_ids, max_concurrent_requests=10):\n",
    "```\n",
    "Essa função gerencia a execução assíncrona para buscar informações dos repositórios curtidos pelos usuários.\n",
    "\n",
    "### 6. Função `get_repository_data`\n",
    "```python\n",
    "def get_repository_data(user_ids):\n",
    "```\n",
    "Função wrapper para chamar a versão assíncrona de maneira síncrona.\n",
    "\n",
    "### 7. Carregamento de IDs e Salvamento dos Dados\n",
    "```python\n",
    "users_ids = pd.read_csv(f\"{base_path}/users_ids.csv\", encoding='utf-8')\n",
    "users_ids = users_ids['user_id'].to_list()\n",
    "```\n",
    "Os IDs dos usuários são lidos de um arquivo CSV, e os dados extraídos são salvos em dois arquivos CSV no caminho definido por `base_path`.\n",
    "\n",
    "**Fluxo Completo:**\n",
    "1. Lê a lista de IDs de usuários do GitHub a partir de um CSV.\n",
    "2. Executa a busca de repositórios curtidos de forma assíncrona.\n",
    "3. Filtra os dados mantendo apenas as chaves relevantes.\n",
    "4. Salva os dados extraídos em dois arquivos CSV:\n",
    "   - `starred_repos_data.csv`: Contém informações dos repositórios curtidos.\n",
    "   - `starred_repos_users_ids.csv`: Contém os IDs dos usuários e os IDs dos repositórios correspondentes.\n",
    "\n",
    "### 8. Uso de Variáveis de Ambiente\n",
    "O script requer duas variáveis de ambiente:\n",
    "- `GITHUB_TOKEN`: Token de acesso à API do GitHub.\n",
    "- `DIR_NAME`: Nome do diretório base para armazenamento dos dados processados.\n",
    "\n",
    "Certifique-se de defini-las antes de executar o script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853533ee-7551-483f-8435-76916b89fd5b",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731b1b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T20:30:06.099506Z",
     "start_time": "2023-06-18T20:29:58.384438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from tqdm.asyncio import tqdm\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e41706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T06:54:14.241006Z",
     "start_time": "2023-06-24T06:54:13.664958Z"
    }
   },
   "outputs": [],
   "source": [
    "# Patch para permitir aninhamento de loops (útil em Jupyter Notebook)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Lista de chaves relevantes para os dados dos repositórios\n",
    "chaves_relevantes = [\n",
    "    \"id\",\n",
    "    \"name\",\n",
    "    \"full_name\",\n",
    "    \"owner_id\",\n",
    "    \"html_url\",\n",
    "    \"description\",\n",
    "    \"fork\",\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"pushed_at\",\n",
    "    \"homepage\",\n",
    "    \"size\",\n",
    "    \"stargazers_count\",\n",
    "    \"watchers_count\",\n",
    "    \"language\",\n",
    "    \"forks_count\",\n",
    "    \"open_issues_count\",\n",
    "    \"license_key\",\n",
    "    \"license_name\",\n",
    "    \"topics\",\n",
    "    \"default_branch\"\n",
    "]\n",
    "\n",
    "def flatten_dict(data, parent_key=\"\"):\n",
    "    \"\"\"\n",
    "    Achata um dicionário:\n",
    "      - Se o valor for um dicionário, adiciona cada subchave como um novo item, concatenando a chave pai e a subchave com um underscore.\n",
    "      - Se o valor for uma lista, converte a lista para uma string separada por vírgulas.\n",
    "      - Apenas as chaves (ou chaves compostas para subchaves) que estiverem em 'chaves_relevantes' serão mantidas.\n",
    "    \n",
    "    Args:\n",
    "        data (dict): Dicionário original.\n",
    "        parent_key (str): Prefixo para as chaves (usado para dicionários aninhados).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário achatado contendo somente as chaves relevantes.\n",
    "    \"\"\"\n",
    "    flattened = {}\n",
    "    for key, value in data.items():\n",
    "        # Cria a nova chave; se houver parent_key, concatena com underscore.\n",
    "        new_key = f\"{parent_key}_{key}\" if parent_key else key\n",
    "        \n",
    "        if isinstance(value, dict):\n",
    "            # Para cada subchave, cria uma chave composta e verifica se ela está em chaves_relevantes.\n",
    "            for sub_key, sub_value in value.items():\n",
    "                composite_key = f\"{new_key}_{sub_key}\"\n",
    "                if composite_key in chaves_relevantes:\n",
    "                    flattened[composite_key] = sub_value\n",
    "        elif isinstance(value, list):\n",
    "            # Se a chave estiver entre as relevantes, converte a lista para string.\n",
    "            if new_key in chaves_relevantes:\n",
    "                flattened[new_key] = \", \".join(str(item) for item in value)\n",
    "        else:\n",
    "            if new_key in chaves_relevantes:\n",
    "                flattened[new_key] = value\n",
    "    return flattened\n",
    "\n",
    "async def fetch_repos_for_user(session, user_id, semaphore, timeout=1000):\n",
    "    \"\"\"\n",
    "    Busca os dados de repositórios de um usuário, tratando a paginação.\n",
    "    Após a recuperação, cada dicionário de repositório é achatado pela função flatten_dict,\n",
    "    mantendo somente as chaves relevantes.\n",
    "    \n",
    "    Args:\n",
    "        session (aiohttp.ClientSession): Sessão HTTP.\n",
    "        user_id (str ou int): ID do usuário no GitHub.\n",
    "        semaphore (asyncio.Semaphore): Semáforo para limitar requisições concorrentes.\n",
    "        timeout (int): Tempo máximo de espera da requisição.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário com o user_id como chave e a lista de repositórios achatados (somente com as chaves relevantes) como valor.\n",
    "    \"\"\"\n",
    "    url = f\"https://api.github.com/user/{user_id}/starred\"\n",
    "    params = {'per_page': 100, 'page': 1}\n",
    "    repos = []\n",
    "\n",
    "    async with semaphore:\n",
    "        while url:\n",
    "            try:\n",
    "                async with session.get(url, params=params, timeout=timeout) as response:\n",
    "                    if response.status == 200:\n",
    "                        page_data = await response.json()\n",
    "                        repos.extend(page_data)\n",
    "                        # Verifica se há próxima página (paginação)\n",
    "                        if 'next' in response.links:\n",
    "                            url = response.links['next']['url']\n",
    "                            params = {}  # A URL já contém os parâmetros necessários\n",
    "                        else:\n",
    "                            url = None\n",
    "                    else:\n",
    "                        print(f\"Erro na requisição para o usuário {user_id}: {response.status}\")\n",
    "                        break\n",
    "            except asyncio.TimeoutError:\n",
    "                print(f\"Timeout na requisição para o usuário {user_id}\")\n",
    "                break\n",
    "\n",
    "    # Aplica a função de flatten em cada repositório, mantendo somente as chaves relevantes.\n",
    "    flattened_repos = [flatten_dict(repo) for repo in repos]\n",
    "    return {user_id: flattened_repos}\n",
    "\n",
    "async def get_repository_data_async(user_ids, max_concurrent_requests=10):\n",
    "    \"\"\"\n",
    "    Recupera de forma assíncrona os dados dos repositórios para uma lista de usuários,\n",
    "    mantendo somente as chaves relevantes definidas em 'chaves_relevantes'.\n",
    "    \n",
    "    Args:\n",
    "        user_ids (list): Lista de IDs de usuários no GitHub.\n",
    "        max_concurrent_requests (int): Número máximo de requisições HTTP concorrentes.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário mapeando cada user_id à sua lista de repositórios achatados (filtrados).\n",
    "    \"\"\"\n",
    "    token = os.getenv('GITHUB_TOKEN')\n",
    "    if not token:\n",
    "        raise ValueError(\"A variável de ambiente GITHUB_TOKEN não está definida.\")\n",
    "\n",
    "    headers = {\n",
    "        'Authorization': f'Token {token}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "\n",
    "    semaphore = asyncio.Semaphore(max_concurrent_requests)\n",
    "    results = {}\n",
    "\n",
    "    async with aiohttp.ClientSession(headers=headers) as session:\n",
    "        tasks = [fetch_repos_for_user(session, uid, semaphore) for uid in user_ids]\n",
    "        for coro in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"Processando Usuários\"):\n",
    "            user_repo_data = await coro\n",
    "            results.update(user_repo_data)\n",
    "\n",
    "    return results\n",
    "\n",
    "def get_repository_data(user_ids):\n",
    "    \"\"\"\n",
    "    Wrapper síncrono para recuperar os dados dos repositórios dos usuários do GitHub.\n",
    "    \n",
    "    Args:\n",
    "        user_ids (list): Lista de IDs de usuários do GitHub.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário mapeando cada user_id à sua lista de repositórios achatados (filtrados).\n",
    "    \"\"\"\n",
    "    return asyncio.run(get_repository_data_async(user_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13b1d636-6b7b-4459-9b1f-1bd0f5724901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Usuários: 100%|██████████| 2029/2029 [02:40<00:00, 12.67it/s]\n"
     ]
    }
   ],
   "source": [
    "dir_name = os.getenv('DIR_NAME')\n",
    "base_path = f'../data/{dir_name}'\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "users_ids = pd.read_csv(f\"{base_path}/users_data.csv\", encoding='utf-8')\n",
    "users_ids = users_ids['id'].to_list()\n",
    "\n",
    "filename = f\"{base_path}/starred_repos_data.csv\"\n",
    "ids_filename = f\"{base_path}/starred_repos_users_ids.csv\"\n",
    "\n",
    "stared_data = get_repository_data(users_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10e3d1a-3004-4f85-a6b6-39fe5dfda6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravados dados de 17705 repositórios curtidos.\n"
     ]
    }
   ],
   "source": [
    "repos_list = []\n",
    "ids_list = []\n",
    "for user_id, repos in stared_data.items():\n",
    "    for repo in repos:\n",
    "        repos_list.append(repo)\n",
    "\n",
    "        repo_id = repo.get(\"id\")\n",
    "        owner_id = repo.get(\"owner_id\")\n",
    "        ids_list.append({\"user_id\": user_id, \"repo_id\": repo_id, \"owner_id\": owner_id})\n",
    "\n",
    "\n",
    "stared_df = pd.DataFrame(repos_list)\n",
    "ids_df = pd.DataFrame(ids_list)\n",
    "\n",
    "stared_df.to_csv(filename, index=False, encoding='utf-8')\n",
    "stared_df.drop_duplicates(subset='id', inplace=True)\n",
    "\n",
    "ids_df.to_csv(ids_filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f'Gravados dados de {len(stared_df)} repositórios curtidos.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b8eb60-c46c-47b6-8420-7a4bf13ea2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
