{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3bb235b-e36f-46cd-8aa0-84d44e3e20d9",
   "metadata": {},
   "source": [
    "# Documentação: Coleta de Issues do GitHub\n",
    "\n",
    "## Introdução\n",
    "Este script recupera informações sobre as issues de repositórios do GitHub de forma assíncrona. Ele filtra apenas as chaves relevantes e salva os dados processados em um arquivo CSV.\n",
    "\n",
    "## Dependências\n",
    "Antes de executar o script, instale as bibliotecas necessárias:\n",
    "\n",
    "```bash\n",
    "pip install aiohttp nest_asyncio pandas tqdm\n",
    "```\n",
    "\n",
    "## Estrutura do Script\n",
    "\n",
    "### 1. Configuração do Loop Assíncrono\n",
    "```python\n",
    "nest_asyncio.apply()\n",
    "```\n",
    "Em ambientes como Jupyter Notebook, é necessário aplicar `nest_asyncio` para evitar conflitos com o loop de eventos assíncrono.\n",
    "\n",
    "### 2. Definição das Chaves Relevantes\n",
    "```python\n",
    "chaves_relevantes = [\"repo_id\", \"id\", \"number\", \"title\", \"user_id\", \"state\", \"comments\", \"created_at\", \"updated_at\", \"closed_at\", \"body\", \"reactions_total_count\"]\n",
    "```\n",
    "Define quais informações serão extraídas das issues de repositórios do GitHub.\n",
    "\n",
    "### 3. Função `flatten_issue`\n",
    "```python\n",
    "def flatten_issue(issue, parent_key=\"\"):\n",
    "```\n",
    "Essa função achata um dicionário aninhado, transformando listas em strings separadas por vírgulas e mantendo apenas as chaves relevantes.\n",
    "\n",
    "### 4. Função `fetch_issues_for_repo`\n",
    "```python\n",
    "async def fetch_issues_for_repo(session, repo_id, semaphore, timeout=1000):\n",
    "```\n",
    "Essa função busca as issues de um repositório no GitHub, tratando a paginação e aplicando a função `flatten_issue` para manter apenas as chaves relevantes.\n",
    "\n",
    "### 5. Função `get_issues_data_async`\n",
    "```python\n",
    "async def get_issues_data_async(repo_ids, max_concurrent_requests=10):\n",
    "```\n",
    "Essa função gerencia a execução assíncrona para buscar informações das issues de múltiplos repositórios.\n",
    "\n",
    "### 6. Função `get_issues_data`\n",
    "```python\n",
    "def get_issues_data(repo_ids):\n",
    "```\n",
    "Função wrapper para chamar a versão assíncrona de maneira síncrona.\n",
    "\n",
    "### 7. Carregamento de IDs e Salvamento dos Dados\n",
    "```python\n",
    "repos_ids = pd.read_csv(f\"{base_path}/repos_data.csv\", encoding='utf-8')\n",
    "repos_ids = repos_ids['id'].to_list()\n",
    "```\n",
    "Os IDs dos repositórios são lidos de um arquivo CSV, e os dados extraídos são salvos em um novo arquivo CSV no caminho definido por `base_path`.\n",
    "\n",
    "**Fluxo Completo:**\n",
    "1. Lê a lista de IDs de repositórios do GitHub a partir de um CSV.\n",
    "2. Executa a busca de issues de forma assíncrona.\n",
    "3. Filtra os dados mantendo apenas as chaves relevantes.\n",
    "4. Salva os dados extraídos em um arquivo CSV:\n",
    "   - `issues_data.csv`: Contém informações das issues coletadas.\n",
    "\n",
    "### 8. Uso de Variáveis de Ambiente\n",
    "O script requer duas variáveis de ambiente:\n",
    "- `GITHUB_TOKEN`: Token de acesso à API do GitHub.\n",
    "- `DIR_NAME`: Nome do diretório base para armazenamento dos dados processados.\n",
    "\n",
    "Certifique-se de defini-las antes de executar o script.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbe8187-3171-4f48-883f-67b3a94f1930",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "731b1b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-18T20:30:06.099506Z",
     "start_time": "2023-06-18T20:29:58.384438Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from tqdm.asyncio import tqdm\n",
    "import nest_asyncio\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e41706",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-24T06:54:14.241006Z",
     "start_time": "2023-06-24T06:54:13.664958Z"
    }
   },
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "# Lista de chaves relevantes que desejamos coletar de cada issue.\n",
    "chaves_relevantes = [\n",
    "    \"repo_id\",           # Valor extraído do parâmetro da função\n",
    "    \"id\",\n",
    "    \"number\",\n",
    "    \"title\",\n",
    "    \"user_id\",\n",
    "    \"state\",\n",
    "    \"comments\",\n",
    "    \"created_at\",\n",
    "    \"updated_at\",\n",
    "    \"closed_at\",\n",
    "    \"body\",\n",
    "    \"reactions_total_count\",\n",
    "]\n",
    "\n",
    "def flatten_issue(issue, parent_key=\"\"):\n",
    "    \"\"\"\n",
    "    Achata um dicionário de issue:\n",
    "      - Se o valor for um dicionário, adiciona cada subchave como um novo item concatenando a chave pai e a subchave com underscore.\n",
    "      - Se o valor for uma lista, converte a lista para uma string (itens separados por vírgula).\n",
    "      - Apenas as chaves (ou chaves compostas para subchaves) que estiverem em 'chaves_relevantes' serão mantidas.\n",
    "    \n",
    "    Args:\n",
    "        issue (dict): Dicionário original da issue.\n",
    "        parent_key (str): Prefixo para as chaves (para dicionários aninhados).\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário achatado contendo somente as chaves relevantes.\n",
    "    \"\"\"\n",
    "    flattened = {}\n",
    "    for key, value in issue.items():\n",
    "        # Cria a chave com prefixo se houver parent_key\n",
    "        new_key = f\"{parent_key}_{key}\" if parent_key else key\n",
    "\n",
    "        if isinstance(value, dict):\n",
    "            # Para cada subchave, cria a chave composta e verifica se ela é relevante.\n",
    "            for sub_key, sub_value in value.items():\n",
    "                composite_key = f\"{new_key}_{sub_key}\"\n",
    "                if composite_key in chaves_relevantes:\n",
    "                    flattened[composite_key] = sub_value\n",
    "        elif isinstance(value, list):\n",
    "            # Se a chave for relevante, converte a lista em uma string separada por vírgulas.\n",
    "            if new_key in chaves_relevantes:\n",
    "                flattened[new_key] = \", \".join(str(item) for item in value)\n",
    "        else:\n",
    "            if new_key in chaves_relevantes:\n",
    "                flattened[new_key] = value\n",
    "    return flattened\n",
    "\n",
    "async def fetch_issues_for_repo(session, repo_id, semaphore, timeout=1000):\n",
    "    \"\"\"\n",
    "    Busca os dados de issues de um repositório (identificado pelo seu ID),\n",
    "    tratando a paginação e aplicando o flattening nos dados, mantendo somente as chaves relevantes.\n",
    "    \n",
    "    Args:\n",
    "        session (aiohttp.ClientSession): Sessão HTTP.\n",
    "        repo_id (int ou str): ID do repositório.\n",
    "        semaphore (asyncio.Semaphore): Para limitar o número de requisições concorrentes.\n",
    "        timeout (int): Timeout para a requisição.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dicionário com o repo_id como chave e a lista de issues achatadas como valor.\n",
    "    \"\"\"\n",
    "    # URL para coletar as issues a partir do ID do repositório.\n",
    "    url = f\"https://api.github.com/repositories/{repo_id}/issues\"\n",
    "    params = {'per_page': 100, 'page': 1}\n",
    "    issues = []\n",
    "\n",
    "    async with semaphore:\n",
    "        while url:\n",
    "            try:\n",
    "                async with session.get(url, params=params, timeout=timeout) as response:\n",
    "                    if response.status == 200:\n",
    "                        page_data = await response.json()\n",
    "                        issues.extend(page_data)\n",
    "                        # Trata paginação: se houver link 'next', atualiza a URL.\n",
    "                        if 'next' in response.links:\n",
    "                            url = response.links['next']['url']\n",
    "                            params = {}  # A URL já contém os parâmetros necessários\n",
    "                        else:\n",
    "                            url = None\n",
    "                    else:\n",
    "                        print(f\"Erro na requisição para o repositório {repo_id}: {response.status}\")\n",
    "                        break\n",
    "            except asyncio.TimeoutError:\n",
    "                print(f\"Timeout na requisição para o repositório {repo_id}\")\n",
    "                break\n",
    "\n",
    "    flattened_issues = []\n",
    "    for issue in issues:\n",
    "        flat_issue = flatten_issue(issue)\n",
    "        # Adiciona o repo_id à issue (caso não esteja presente)\n",
    "        flat_issue[\"repo_id\"] = repo_id\n",
    "        flattened_issues.append(flat_issue)\n",
    "    return {repo_id: flattened_issues}\n",
    "\n",
    "async def get_issues_data_async(repo_ids, max_concurrent_requests=10):\n",
    "    \"\"\"\n",
    "    Recupera de forma assíncrona os dados de issues para uma lista de repositórios,\n",
    "    mantendo somente as chaves relevantes definidas em 'chaves_relevantes'.\n",
    "    \n",
    "    Args:\n",
    "        repo_ids (list): Lista de IDs de repositórios.\n",
    "        max_concurrent_requests (int): Número máximo de requisições concorrentes.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dicionário mapeando cada repo_id à sua lista de issues achatadas.\n",
    "    \"\"\"\n",
    "    token = os.getenv('GITHUB_TOKEN')\n",
    "    if not token:\n",
    "        raise ValueError(\"A variável de ambiente GITHUB_TOKEN não está definida.\")\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Token {token}',\n",
    "        'Accept': 'application/vnd.github.v3+json'\n",
    "    }\n",
    "    \n",
    "    semaphore = asyncio.Semaphore(max_concurrent_requests)\n",
    "    results = {}\n",
    "    \n",
    "    async with aiohttp.ClientSession(headers=headers) as session:\n",
    "        tasks = [fetch_issues_for_repo(session, repo_id, semaphore) for repo_id in repo_ids]\n",
    "        for coro in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"Processando Repositórios\"):\n",
    "            repo_issue_data = await coro\n",
    "            results.update(repo_issue_data)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def get_issues_data(repo_ids):\n",
    "    \"\"\"\n",
    "    Função wrapper síncrona para recuperar os dados de issues para uma lista de repositórios.\n",
    "    \n",
    "    Args:\n",
    "        repo_ids (list): Lista de IDs de repositórios.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Dicionário mapeando cada repo_id à sua lista de issues achatadas.\n",
    "    \"\"\"\n",
    "    return asyncio.run(get_issues_data_async(repo_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9f9ff64-12f5-4920-9418-8f14631ace84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processando Repositórios: 100%|██████████| 1001/1001 [00:48<00:00, 20.73it/s]\n"
     ]
    }
   ],
   "source": [
    "dir_name = os.getenv('DIR_NAME')\n",
    "base_path = f'../data/{dir_name}'\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "repos_ids = pd.read_csv(f\"{base_path}/repos_data.csv\", encoding='utf-8')\n",
    "repos_ids = repos_ids[repos_ids['open_issues_count'] > 0]['id'].to_list()\n",
    "\n",
    "filename = f\"{base_path}/issues_data.csv\"\n",
    "issues_data = get_issues_data(repos_ids) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10e3d1a-3004-4f85-a6b6-39fe5dfda6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gravados dados de 5307 issues.\n"
     ]
    }
   ],
   "source": [
    "issues_list = []\n",
    "for repo_id, issues in issues_data.items():\n",
    "    for issue in issues:\n",
    "        issues_list.append(issue)\n",
    "\n",
    "\n",
    "issues_df = pd.DataFrame(issues_list)\n",
    "issues_df.to_csv(filename, index=False, encoding='utf-8')\n",
    "\n",
    "print(f'Gravados dados de {len(issues_df)} issues.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7b9a10-5977-46fe-b29e-df311bec9e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
